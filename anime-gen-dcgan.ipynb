{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "from keras.layers import Dense, Conv2D, Conv2DTranspose, Dropout, Reshape, Input, merge\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.initializers import RandomNormal\n",
    "K.set_image_dim_ordering('tf')\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True \n",
    "set_session(tf.Session(config=config))\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and visualize a sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('data/animeface-character-dataset/thumb/*/*.png')\n",
    "\n",
    "print(\"Number of images: \", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i in range(5):\n",
    "    img = plt.imread(filenames[i], 0)\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(img.shape)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(img):\n",
    "    '''A function to normalize images\n",
    "    Input:\n",
    "        img: Original image as numpy array\n",
    "    Output:\n",
    "        img: Normalized image as numpy array\n",
    "    '''\n",
    "    return (img / 127.5) - 1\n",
    "\n",
    "def denorm_img(img):\n",
    "    '''A function to return the image to original form\n",
    "    Input:\n",
    "        img: Normalized image as numpy array\n",
    "    Output:\n",
    "        img: Image in original form as numpy array\n",
    "    '''\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def sample_from_dataset(batch_size, image_shape, data_dir=None):\n",
    "    '''Create a batch of image samples by sampling random images from a data directory.\n",
    "    Resizes the image using image_shape and normalize the images.\n",
    "    Input:\n",
    "        batch_size : Sample size required\n",
    "        image_size : Size that Image should be resized to\n",
    "        data_dir : Path of directory where training images are placed.\n",
    "\n",
    "    Output:\n",
    "        sample : batch of processed images \n",
    "    '''\n",
    "    sample_dim = (batch_size), + image_shape\n",
    "    sample = np.empty(sample_dim, dtype=np.float32)\n",
    "    all_data_dirlist = list(glob.glob(data_dir))\n",
    "    sample_imgs_paths = np.random.choice(all_data_dirlist, batch_size)\n",
    "    for index, img_filename in enumerate(sample_imgs_paths):\n",
    "        image = Image.open(img_filename)\n",
    "        image = image.resize(image_shape[:-1])\n",
    "        image = image.convert('RGB')\n",
    "        image = np.asarray(image)\n",
    "        image = norm_img(image)\n",
    "        sample[index,...] = image\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implemenation of DCGAN\n",
    "\n",
    "## 1. Generate noise vector of Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, noise_shape):\n",
    "    ''' Generates a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)\n",
    "    Input:\n",
    "        batch_size : size of batch\n",
    "        noise_shape: shape of noise vector, normally kept as 100 \n",
    "    Output:a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)     \n",
    "    '''\n",
    "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Generator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_normal(noise_shape):\n",
    "    '''This function takes an input the shape of the noise vector and creates the Keras generator architecture\n",
    "    '''\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    gen_input = Input(shape=noise_shape)\n",
    "    \n",
    "    # Transpose 2D Conv layer 1\n",
    "    generator = Conv2DTranspose(filters=512, kernel_size=(4,4), strides=(1,1), padding=\"valid\", data_format=\"channels_last\", kernel_initializer=kernel_init)(gen_input)\n",
    "    generator = BatchNormalization(momentum=0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Transpose 2D Conv layer 2\n",
    "    generator = Conv2DTranspose(filters=256, kernel_size=(4,4), strides=(2,2), padding=\"same\", data_format=\"channels_last\", kernel_initializer=kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum=0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Transpose 2D Conv layer 3\n",
    "    generator = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding=\"same\", data_format=\"channels_last\", kernel_initializer=kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum=0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Transpose 2D Conv layer 4\n",
    "    generator = Conv2DTranspose(filters=64, kernel_size=(4,4), strides=(2,2), padding=\"same\", data_format=\"channels_last\", kernel_initializer=kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum=0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # 2D Conv layer 1\n",
    "    generator = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\", data_format=\"channels_last\", kernel_initializer=kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum=0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Final Transpose 2D conv layer 5 to generate final image. Filter size 3 for 3 image channel\n",
    "    generator = Conv2DTranspose(filters = 3, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    \n",
    "    # Tanh activation to get final normalized image\n",
    "    generator = Activation(\"tanh\")(generator)\n",
    "    \n",
    "    # Defining the optimizer and compiling the generator model\n",
    "    gen_opt = Adam(lr=0.00015, beta_1=0.5)\n",
    "    generator_model = Model(input=gen_input, output=generator)\n",
    "    generator_model.compile(loss=\"binary_crossentropy\", optimizer=gen_opt, metrics=[\"accuracy\"])\n",
    "    generator_model.summary()\n",
    "    \n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
